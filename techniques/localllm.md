## things I tried:
1. ollama
2. llama.cpp
3. lm studio

3 is by far better than the first 2. 
1. llama.cpp seems optimized for cpu, and, it cannot list the gpu I have on windows as a device. (lm studio automatically recognizes my gpu). 
2. ollama is just confusing, first, I cannot choose where to install it, and where to place the models, it is just terrible for windows


